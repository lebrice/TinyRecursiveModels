# This CITATION.cff file was generated with cffinit.
# Visit https://bit.ly/cffinit to generate yours today!

cff-version: 1.2.0
title: "Less is More: Recursive Reasoning with Tiny Networks"
message: >-
  If you use this software, please cite it using the
  metadata from this file.
type: software
authors:
  - {}
  - given-names: Alexia
    family-names: Jolicoeur-Martineau
    email: alexia.j@samsung.com
    affiliation: Samsung SAIL MontrÃ©al
    orcid: "https://orcid.org/0000-0003-2169-4008"
identifiers:
  - type: url
    value: "https://arxiv.org/abs/2510.04871"
    description: Arxiv URL
  - type: url
    value: >-
      https://github.com/SamsungSAILMontreal/TinyRecursiveModels
    description: Source code
repository-code: "https://github.com/SamsungSAILMontreal/TinyRecursiveModels"
abstract: >-
  Hierarchical Reasoning Model (HRM) is a novel approach
  using two small neural networks recursing at different
  frequencies. This biologically inspired method beats Large
  Language models (LLMs) on hard puzzle tasks such as
  Sudoku, Maze, and ARC-AGI while trained with small models
  (27M parameters) on small data (around 1000 examples). HRM
  holds great promise for solving hard problems with small
  networks, but it is not yet well understood and may be
  suboptimal. We propose Tiny Recursive Model (TRM), a much
  simpler recursive reasoning approach that achieves
  significantly higher generalization than HRM, while using
  a single tiny network with only 2 layers. With only 7M
  parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and
  8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1,
  o3-mini, Gemini 2.5 Pro) with less than 0.01% of the
  parameters.
license: MIT
